#!/usr/bin/env python3
"""
æå–Futurex-Pastç»“æœå¹¶ç”ŸæˆCSVæ–‡ä»¶
æå–å­—æ®µ: task_id, task_description, end_time, level, final_boxed_answer, ground_truth
"""

import json
import csv
import re
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple

def extract_boxed_answer(text: str) -> str:
    """ä»æ–‡æœ¬ä¸­æå–\\boxed{...}ä¸­çš„å†…å®¹ï¼Œä»åå¾€å‰åŒ¹é…æœ€åä¸€ä¸ªboxed"""
    if not text:
        return ""
    
    # åŒ¹é… \boxed{...} æ ¼å¼ï¼Œä½¿ç”¨findallæ‰¾åˆ°æ‰€æœ‰åŒ¹é…
    pattern = r'\\boxed\{([^{}]*(?:\{[^{}]*\}[^{}]*)*)\}'
    matches = re.findall(pattern, text)
    
    # å¦‚æœæœ‰åŒ¹é…ï¼Œè¿”å›æœ€åä¸€ä¸ªï¼ˆå³ä»åå¾€å‰ç¬¬ä¸€ä¸ªï¼‰
    if matches:
        return matches[-1].strip()
    return ""

def process_json_files(directory: str) -> List[Dict]:
    """å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶ï¼Œæå–å…³é”®ä¿¡æ¯"""
    results = []
    dir_path = Path(directory)
    
    # è·å–æ‰€æœ‰JSONæ–‡ä»¶
    json_files = list(dir_path.glob("task_*_attempt_1.json"))
    print(f"æ‰¾åˆ° {len(json_files)} ä¸ªä»»åŠ¡æ–‡ä»¶")
    
    for file_path in json_files:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                
                # æå–åŸºæœ¬ä¿¡æ¯
                task_id = data.get("task_id", "")
                task_description = data.get("input", {}).get("task_description", "")
                
                # ç­›é€‰task_descriptionï¼Œåªä¿ç•™CRITICAL TIME CONSTRAINTä¹‹å‰çš„éƒ¨åˆ†
                critical_marker = "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nğŸ”´ CRITICAL TIME CONSTRAINT - MUST FOLLOW"
                if critical_marker in task_description:
                    task_description = task_description.split(critical_marker)[0].strip()

                # æå–metadata
                metadata = data.get("input", {}).get("metadata", {})
                end_time = metadata.get("end_time", "")
                level = metadata.get("level", "")
                
                # æå–ç­”æ¡ˆ
                final_answer = ""
                # ä»step_logsä¸­æŸ¥æ‰¾final_answer_content
                step_logs = data.get("step_logs", [])
                for step in step_logs:
                    if step.get("step_name") == "final_answer_content":
                        final_answer = step.get("message", "")
                        break
                
                boxed_content = extract_boxed_answer(final_answer)
                if not boxed_content:
                    comleted_status = "failed"
                else:
                    comleted_status = "completed"
                
                # æå–ground truth
                ground_truth = data.get("ground_truth", "")
                
                # è®¡ç®—è€—æ—¶
                start_time = data.get("start_time", "")
                end_time_exec = data.get("end_time", "")
                duration = ""
                if start_time and end_time_exec:
                    try:
                        start = datetime.fromisoformat(start_time)
                        end = datetime.fromisoformat(end_time_exec)
                        duration = str((end - start).total_seconds())
                    except:
                        pass

                # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                results.append({
                    "task_id": task_id,
                    "task_description": task_description,
                    "end_time": end_time,
                    "level": level,
                    "final_answer": final_answer,
                    "boxed_content": boxed_content,
                    "ground_truth": ground_truth,
                    "duration_seconds": duration,
                    "completion_status": comleted_status
                })
        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
    
    return results

def save_to_csv(results: List[Dict], output_file_path: str):
    """å°†ç»“æœä¿å­˜ä¸ºCSVæ–‡ä»¶ï¼Œä»…ä¿å­˜å·²å®Œæˆçš„ä»»åŠ¡"""
    if not results:
        print("æ²¡æœ‰ç»“æœå¯ä¿å­˜")
        return
    
    # ç­›é€‰å‡ºå·²å®Œæˆçš„ä»»åŠ¡
    completed_results = [r for r in results if r.get("completion_status") == "completed"]
    
    if not completed_results:
        print("æ²¡æœ‰å·²å®Œæˆçš„ä»»åŠ¡ç»“æœå¯ä¿å­˜")
        return
    
    # å®šä¹‰CSVåˆ—é¡ºåº
    fieldnames = [
        "task_id", "task_description", "level", "end_time",
        "ground_truth", "final_answer", "boxed_content", "duration_seconds", 
        "completion_status"
    ]
    
    with open(output_file_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(completed_results)
    
    print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file_path}")
    print(f"å…±ä¿å­˜äº† {len(completed_results)} æ¡å·²å®Œæˆçš„ä»»åŠ¡ç»“æœ")

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®è¾“å…¥å’Œè¾“å‡ºè·¯å¾„
    input_dir = "logs/futurex_past_fast"
    output_file = "futurex_past_fast_results.csv"
    output_file_path = os.path.join(input_dir, output_file)
    
    # å¤„ç†æ–‡ä»¶
    print(f"æ­£åœ¨å¤„ç†ç›®å½•: {input_dir}")
    results = process_json_files(input_dir)
    
    # ä¿å­˜ç»“æœ
    save_to_csv(results, output_file_path)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    # æ ¹æ®æ˜¯å¦æœ‰boxed_contentæ¥åˆ¤æ–­æ˜¯å¦å®Œæˆ
    completed = sum(1 for r in results if r["completion_status"] == "completed")
    not_completed = len(results) - completed
    
    print("\nç»Ÿè®¡ä¿¡æ¯:")
    print(f"- æ€»ä»»åŠ¡æ•°: {len(results)}")
    print(f"- å·²å®Œæˆ(æœ‰boxedç»“æœ): {completed}")
    print(f"- æœªå®Œæˆ/è¿›è¡Œä¸­: {not_completed}")
    
    if completed > 0:
        # è®¡ç®—å¹³å‡è€—æ—¶
        durations = [float(r["duration_seconds"]) for r in results if r["boxed_content"] and r["duration_seconds"]]
        if durations:
            avg_duration = sum(durations) / len(durations)
            print(f"\nå¹³å‡è€—æ—¶: {avg_duration:.1f}ç§’ ({avg_duration/60:.1f}åˆ†é’Ÿ)")

if __name__ == "__main__":
    main()
